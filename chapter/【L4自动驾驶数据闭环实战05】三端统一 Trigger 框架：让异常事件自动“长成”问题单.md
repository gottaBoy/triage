系列小结：
01：最重要的第一步——给整个组织选对 Loss Function（MPI / MPS / MPD）。
02：L4 无人车的实时打点与业务心跳。
03：自动驾驶数据闭环的“地基工程”：数据分级上传与 Case / 文件映射。
04：每车每秒的标签体系与 FastDM / FreeDM 的历史数据挖掘。
前四篇更多在搭“地基”和“管道”。从这一篇开始，我们正式走到中枢神经——
异常事件如何被自动发现、自动归因、自动长成问题单，并最终汇总成头部问题。
这一切的核心，就是一个三端统一的 Trigger 框架。

一、从“看 log 找 bug”到“数据自己长成问题单”
在很多自动驾驶团队里，问题排查的原始形态大概是这样：

车上出了一次急刹车 / 大转向 / 停车不走；
运维 / 研发打开回放系统，盯着一堆 log 窗口：
感知障碍物框；
预测轨迹；
规划选路；
控制指令；
底盘 CAN、错误码……
凭经验判断：
“这个更像感知漏检”；
“这个是规划犹豫”；
“这个是底盘异常”；
然后手动在问题管理系统里提工单、选模块、分配给某位同学。
这种方式的问题你自己也体会过：

1.强依赖少数“老法师”

经验全在几个人脑子里，很难系统化沉淀；
人一换，诊断质量大概率掉一截。
2.云 / 车 / 仿真三套逻辑各写一遍

车端写一套在线监控逻辑；
云端挖历史数据又写一套；
仿真评测再写一套。
名义上都是“急刹车判断”，细节阈值却不一样，结论经常打架。
3.问题聚类和头部问题发现很难做

每次排查都是一个个“散点”；
很难系统性回答： > “这个月我们最该优先解决的头部问题究竟是哪几类？”
如果把整个组织类比成一个“强化学习系统”：

MPI / MPS / MPD 是顶层的 Loss Function；
每一次异常 / bug，其实都是推动系统学习的一次“样本”。
那我们真正想要的是：

异常事件不用人盯着才出现，而是顺着日志自己长成一条条结构化的“问题样本”——
自动发现、自动归因、自动分发，再自动汇总成头部问题。
这就是 Trigger 框架要干的事。

二、先说清楚：Trigger 在这个体系里到底是什么？
在这个系列里，“Trigger”这个词已经出现了很多次。在这一篇里，我们给它一个稍微“学术一点”的定义：

Trigger = 特征工程 + Tokenizer
问题分类 = Token 序列上的 Classifier
特征工程（Feature Engineering）
从原始日志（姿态、感知结果、轨迹、底盘 CAN、错误码、模块中间结果……）中，抽取一批“中间事件”：
“第 3 秒，前方某个障碍物的尺寸突然从 1.2m 变成 3.5m”；
“第 5 秒，车辆纵向加速度 < -3.5m/s²，疑似急刹车”；
“第 7 秒，控制输出方向盘角度瞬间跳变，超过某个阈值”。
Tokenizer
把这些中间事件，按时间轴打成一个个“Token”：
每个 Token 带上类型（比如 perception_box_jump）、时间戳、附加属性（距离、速度、类别等）。
Classifier
对同一个 case 内的一串 Token 序列（加上场景标签），去判断：
这是感知漏检？
还是误检导致的急刹？
还是 PnC 纵向调节过度？
还是地图 / 路况 / 底盘问题？
Trigger 做的是前半段：把时间序列原始信号变成“可供分类的 Token 序列”。
后面的问题分类、聚类、头部问题分析，都是在这堆 Token / 标签 / Case 上做文章。

三、为什么一定要“三端统一”的 Trigger？
如果不统一，一般会长成这样三套：

1.车端 Trigger（在线监控 + 数据采集）

为了实时性和资源占用，逻辑写得很轻；
语言 / 框架可能跟云端完全不一样。
2.云端 Trigger（历史数据挖掘 + 回溯统计）

通常是 ODPS 上一套 Python UDF + SQL；
负责扫 microlog / mini log 做历史回刷。
3.仿真 Trigger（回归评测）

仿真平台内部再写一套 case 触发和评测的逻辑。
结果就是：

同一个“急刹车”的定义，三处阈值略不同；
同一段数据，仿真里是 OK，线上算 Bad，怎么都对不齐；
出了问题之后，扯皮成本巨大。
所以三端统一 Trigger 的目标非常朴素：

关于“什么算一次事件 / 什么算一个问题”的逻辑，只写一份 Trigger 代码，
云端 / 车端 / 仿真三端都用这一份。
四、Trigger 框架总体设计：一套 Python，三端 Runtime
在实现上，我给 Trigger 做了两个“死规定”：

Trigger 逻辑必须用纯 Python 写，遵守一套统一接口；
多端适配、性能优化、可视化增强，全部藏在框架里，业务同学只写 Trigger。
整体分成三层：

Trigger 定义层（元数据 + 文档）
Trigger Runtime（执行引擎）
Trigger 管理与调度（Manager + 发布系统）
4.1 Trigger 定义层：元数据 + LLM 可读文档
每一个 Trigger 都有自己的“身份证”：

trigger_id：唯一标识；
名称 / 描述；
所属模块（感知 / 预测 / PnC / 定位 / 硬件 / 场景 / 基础设施等）；
输入依赖：
订阅哪些 channel；
需要哪些字段（pose、microlog 字段、障碍物、多边形、轨迹、错误码等）；
输出标签：
生成哪些 Token 类型；
最终会写哪些 case / 标签字段；
复杂度等级：
可以车端在线跑；
还是只能云端 / 仿真离线跑。
另外，还有一份专门给大模型看的“可读文档”，
后面用 LLM 帮忙写 Trigger、做自动归因的时候会用到。

4.2 Trigger Runtime：三端统一的执行接口
Runtime 对 Trigger 提供了一个统一的执行接口，大致是：

init()
eval()
analysis()
与其记细节，不如把这三步当成一个固定“人生三段论”来理解。

4.2.1 init()：声明你要看的数据 + 初始化状态
init() 做两件事：

1.声明数据依赖（订阅 channel）

告诉框架：这一条 Trigger 需要哪些 channel、哪些字段：
pose、车速、加速度、航向角；
microlog 中的算法中间结果；
感知障碍物多边形、预测轨迹；
控制输出、错误码等。
框架用这些订阅信息做两层优化：
云端：在拼 microlog / mini log 时做初筛，只读需要的字段，减少 IO；
车端：只把必要的数据推给 Trigger 沙箱，减少对主流程干扰。
2.初始化 Trigger 级的“全局状态”

在 init() 中定义跨帧需要保存的状态：
比如上一帧的障碍物位置、累计时间、状态机阶段；
这些状态在实现上是 Trigger 实例的成员变量，
在 eval() 中可以不断更新。
简单讲：init() 决定“我要看什么”和“我要记什么”。

4.2.2 eval()：一帧一帧往前走，离线是 for 循环，车端是实时流
eval() 是 Trigger 的主战场。框架保证：

按时间顺序调用：
云端：对一个 case 的数据做 for loop，按时间戳从小到大调用 eval()；
车端：接收到实时 channel 数据，就按顺序回调 eval()；
仿真：在仿真回放时按仿真时间依次调用。
业务逻辑“离线 / 实时无差别”：
对 Trigger 作者来说，写 eval() 不用关心“当前在哪个平台”；
你只需要假设：每次 eval() 被调用，就是又来了一帧时间序列数据。
典型的 eval() 逻辑会：

读这一帧订阅到的各类字段；
和之前的状态做对比（上一帧 / 前几帧）；
判断是否出现某种模式：
盒子突变、轨迹跳变；
加速度异常、方向盘抖动；
某个错误码持续时间超过阈值；
如果命中，就记录一个中间事件（Token）到内部列表。
因为 eval() 调用频繁，性能很关键。
框架已经把很多昂贵的几何运算用 C++ 做了高性能实现，比如：

多边形是否相交；
多边形之间的最小距离；
点到多边形 / 线段的距离等。
Trigger 脚本里只需要调用 Python 接口，例如：

# 伪代码示意
if geom.poly_intersect(poly_a, poly_b):
    self.events.append({
        "ts": ts,
        "type": "perception_poly_intersect",
        "extra": {...}
    })
对 Trigger 作者来说，就是一个普通 Python 函数调用；
对 Runtime 来说，底层实际走的是高性能 C++ 库。

4.2.3 analysis()：一段数据跑完之后做“总结发言”
analysis() 在跑完一段时间片之后调用：

云端 / 离线：
通常以 case 为单位，当这个 case 的所有帧都跑完 eval()，
Runtime 会调用一次 analysis()；
车端 / 实时：
可以配置滑动窗口，比如“每 60 秒 / 每个 road_case 完结时”调用一次。
analysis() 有两个要求：

1.输出一批标准字段

事件类型（例如感知误检导致急刹、PnC 跟车策略保守、定位跳变等）；
关键事件发生的时间点；
所属 road_case_id / bad_case_id；
严重程度、建议归属模块等（如果这个 Trigger 负责分类）。
2.可以输出扩展字段做平台差异化展示

仿真平台上：
可以顺带输出“有问题的时刻截图的路径”、关键状态的可视化信息；
云端离线批处理时：
可以只输出结构化信息，不输出重资源字段，节省存储和带宽。
可以把整套流程理解成：

init()：我要看什么 + 我要记什么；
eval()：每来一帧，我更新状态、记下中间事件；
analysis()：这一段看完了，我输出一个结构化结论。
三个方法接口在云端 / 车端 / 仿真端完全一致，
差异全由 Runtime 层屏蔽。

4.3 急刹 Trigger 也是这么长出来的
前几篇提到的“万公里急刹 MPI”的精确口径，其实背后就是一组 Trigger：

判断急刹的特征：
100Hz 姿态数据上的加速度阈值；
是否过滤掉低速小抖动；
在多帧上积分 / 平滑；
road_case 切片规则：
一分钟内多次急刹算一次 road_case；
用 microlog 回刷 MPI 的精确逻辑。
这些逻辑都在 Trigger 库里固化成代码，经团队内部确认后公示、评审后合入仓库：

云端回刷历史数据 → 执行的是这一套 Trigger；
车端在线检测体感事件 → 执行的还是这一套；
仿真里评测 MPI / 体感指标 → 也是同一套。
所有“急刹怎么算”的争议，都可以直接“对着代码说话”，
不再出现云 / 车 / 仿真口径不一致的情况。

4.4 Trigger 的跨平台执行：甚至可以在纯前端网页里跑
为了让一线同学调试更方便，Trigger 框架在跨平台这件事上做得比较极端：

云端 / 仿真端：
直接在服务端 Python 环境中跑 Trigger；
云端是 ODPS + Python UDF，仿真端是本地 / 集群执行。
车端：
嵌入式 Python + C++ 加速库，运行在沙箱环境里；
与主算法流程隔离，只在闲时 / 限定资源下执行。
纯前端 Web 环境：
使用 JS 版 Python 解释器（例如 Pyodide 这类技术路线），
也可以把 Trigger 脚本加载到浏览器里执行。
这样研发 / QA / 运维可以在一套 Web 工具里做到：

选一个 case；
选择一条 Trigger；
点击“执行”，在浏览器本地就能看到 Token / 事件结果，
完全不需要本地搭 Python 环境，极大降低调试门槛。
4.5 框架库 vs Trigger 库：双仓架构与发布流水线
整个 Trigger 体系在工程上不是一个“大杂烩仓库”，
而是刻意拆成了两个代码库：

框架库：Trigger Runtime + 多端适配 + 性能优化 + 可视化增强
Trigger 逻辑库：具体各类 Trigger 规则，由研发共同维护
4.5.1 框架库：核心 Runtime + 各平台适配
框架本体在一个独立仓库里，由少数几个核心开发维护。包含：

init / eval / analysis 的调度逻辑；
云端 ODPS / 车端 Orin / 仿真平台 / Web 前端 的多端适配；
通用高性能工具（C++ 几何库等），并对外暴露统一 Python 接口；
通用的可视化增强能力。
框架发版流程：

打 Tag → 编译 / 打包成各平台可用执行包；
发布到内部包仓库 / 分发服务；
云端 / 车端 / 仿真在执行 Trigger 时，按指定版本号拉取框架本体。
好处：

Trigger 作者只依赖稳定的框架接口，不需要知道 Orin / ODPS / 浏览器如何适配；
线上定位问题时，只要说明“Trigger 版本 + 框架版本”，就能完整复现环境。
4.5.2 Trigger 逻辑库：研发共建 + CI + 自动化测试
每一条 Trigger 的业务逻辑（急刹、大转向、停车不走、模块级中间结果 Trigger 等），
统一放在另一个仓库：

仓库对算法 / QA / 数据同学开放；
每条 Trigger 有自己的文件 / 元数据；
仓库接入 CI 流水线和自动化测试卡口。
合入流程：

所有修改必须走 CI：
运行框架提供的单元测试 / 回归测试；
校验不会破坏现有 Trigger 行为；
一级指标相关 Trigger 还有专门回归用例；
所有测试通过后，才允许合入主干。
针对需要下发到车端执行的 Trigger，还有一道台架性能闸门：

在台架上用真实 / 录制数据流跑 Trigger；
统计 CPU / 内存 / 带宽消耗；
只有性能达标的 Trigger 才允许打上“可下发车端”的标记。
这样：

Trigger 逻辑可以自由演进，越来越多、越来越复杂；
但跑在车端的那一小撮，都是在性能约束下挑出来的轻量子集；
云端 / 仿真则可以充分使用全部 Trigger 做分析。
4.6 大模型 + RAG：Trigger 编写有了“专属 AI 助手”
Trigger 体系一旦搭好，会有一个自然的演化：
不同模块的同学开始写越来越多的 Trigger。

目前除了一级指标相关少数几条 Trigger，
各模块同学已经写了几百条 Trigger，其中大量用来解析算法中间结果、辅助问题分类。

为了降低 Trigger 的编写门槛，我们干了两件事：

1.把框架说明和示例 Trigger 写成提示词 + 文档

把 init / eval / analysis 的用法、常见模式、注意事项写清楚；
把已经发布的 Trigger（急刹、大转向、停车不走、典型模块问题）整理成知识库。
2.用这些文档 + 历史 Trigger 作为 RAG 知识库，做一个“Trigger 编写助手”

研发同学只需要用自然语言描述需求： > “我要监控感知模块中某类目标，在 3 秒内尺寸变化超过 3 倍，且车辆速度 > 20km/h 的场景。”
AI 助手会：
自动生成 init() 需要订阅的 channel 和字段；
生成 eval() 的状态机骨架代码；
生成 analysis() 的标准输出结构；
参考历史相似 Trigger 的实现，给出可复用片段。
最终效果是：

很多原来只有“资深算法工程师”写得出来的 Trigger，
现在一线研发同学也能快速写出规范实现，
并且通过 CI / 台架闸门后，变成可复用的“可执行经验”。
这些 Trigger 不仅帮助各自团队排查问题，更重要的是：

把原本散落在脑子里的调试经验，沉淀成了代码，
变成整个系统的“知识库 + 工具箱”。
五、从 Trigger 到 Case：异常事件是怎样被“长出来”的？
有了统一 Trigger 之后，一次异常是如何从“体感表现”一路长成结构化的 case 的？

大致流水线是这样：

1.体感 Trigger 发现“可疑事件” → 生成 road_case

例如急刹、大转向、停车不走等一级体感指标；
子 Trigger 在秒级 / 100Hz 姿态数据上扫描，一旦命中，就以“自然分钟”为粒度切出一段时间片；
这一分钟的时间片会被赋予一个 road_case_id，这一分钟内所有命中的 Token 都挂在这个 case 下。
2.microlog & mini log 为 case 提供“证据包”

microlog：无损的姿态 / 算法关键指令二进制包；
mini log：压缩后可视化的最小 channel 集（轨迹、障碍物、红绿灯、车道线等）；
云端根据体感 Trigger 命中情况，决定这一段 case 需要上传 / 保留哪些 microlog / mini log 切片。
3.云端 Trigger 在这段 case 上做“第二轮精细识别”

在 microlog / mini log 的基础上，再跑一轮更复杂的 Trigger：
感知相关（漏检 / 误检 / 尺寸估计错误 / 轨迹跳变）；
PnC 相关（纵向 / 横向振荡、长时间犹豫）；
定位 / 地图 / 硬件相关（定位跳变、地图元素缺失、底盘异常等）。
这些 Trigger 产出的 Token 会补充到 road_case 下。
4.从一个 road_case 拆出多个 bad_case（按模块 / 问题划分）

一个 road_case 可能同时涉及多个模块问题：
感知误检 + PnC 跟车策略保守；
我会从同一个 road_case 派生出多个 bad_case_id：
bad_case_id_p：归感知；
bad_case_id_c：归 PnC；
每个 bad_case 在时间窗 / Token 子集上略有差异，方便分发给对应团队。
5.所有 case / Token / 标签，最终落到统一的数据表上

road_case 表：按体感事件切出来的一分钟级 case；
bad_case 表：按模块 / 问题拆分出来的子 case；
case_token 表：case 内的 Token 序列（时间戳 + 类型 + 属性）；
后续的自动分类、聚类、头部问题统计，都从这里出发。
可以理解为：

Trigger 负责在时间轴上不断产生“局部判断”；
Case / Token / 标签体系把这些局部判断串成了一段段“完整的故事”。
六、问题分类：从规则树到 LLM + Trigger Token 的闭环分类器
有了 Token 序列，剩下的问题就是：

“这一段 case，应该叫什么问题名？该分给哪个团队？严重程度如何？”
6.1 第一阶段：纯规则树分类
最早时，我们用纯规则树做分类：

先看有没有感知类 Token（比如 perception_box_jump）；
再看是否伴随急刹 Token；
再看场景（路口 / 干线 / 场内 / 雨天等）；
一层层 if/else 下去，最终输出：
一级模块（感知 / 预测 / PnC / 定位 / 场景 / 硬件 …）；
二级问题类型（漏检 / 误检 / 尺寸估计错误 / 轨迹跳变 / 刹车超调等）。
优点：可解释，逻辑清晰。
缺点也明显：

规则全靠有经验的人写；
一旦组合情况变多，逻辑树非常难维护；
新问题出现时，很难快速扩展。
6.2 第二阶段：Trigger Token 序列 + LLM 做 Classifier
在积累了足够多 case 之后，我们开始让 LLM 站到规则树肩膀上：

1.把 Trigger 产出的 Token 序列转成“事件脚本”文本

例如：
第 3 秒，前方一辆小客车的感知框宽度从 1.2m 变为 3.5m；
第 4 秒，该目标的速度估计从 10km/h 变为 -5km/h；
第 5 秒，车辆纵向加速度达到 -3.5m/s²，触发急刹；
当前场景：城市园区，非机动车道，周围有多名行人……
再拼上秒级标签（天气、路型、车速范围等）。
2.把这段脚本丢给 LLM，让它输出“问题标签”

模块归属：感知 / 预测 / PnC / 定位 / 硬件 / 场景；
问题类型：漏检 / 误检 / 尺寸估计错误 / 跟车策略保守 / 刹车过猛等；
严重程度：致命 / 严重 / 一般 / 轻微；
建议分发团队 / 责任小组。
3.把自然语言结果映射回结构化字段

用统一 schema，把 LLM 输出的自然语言转换成结构化字段：
problem_module、problem_type、severity、assign_team 等；
回写到 bad_case 表中，对每一条 bad_case 做自动分类。
用前文那句“装一点”的说法：

Trigger 在这里扮演 Tokenizer 的角色，
LLM 扮演 Classifier 的角色。
Trigger 做特征工程 + 时间序列 Token 化；
LLM 在 Token 序列的语义空间中完成分类与归因。
七、自动分类之后：自动提单、自动回归、自动 Close 的工单闭环
仅仅“给每个 case 打上问题标签”还不够，真正有价值的是：

这个问题从被发现，到验证是否已解决，尽量都不需要人反复在系统之间跑腿。
在 Trigger + LLM 自动分类之后，我们又往上叠了一层“工单 + 仿真”的自动闭环。

7.1 自动提 Aone 工单：模块、描述、紧急程度都自动带上
当一条 bad_case 被 LLM 分类好之后，我们会把它自动转成一条结构化工单（以 Aone 为例）：

工单标题：
由 LLM 根据 Token 序列 + 场景标签生成一行摘要；
尽量包含“场景 + 模块 + 表现”，比如： > 【园区-低速-雨天】感知误检消防栓为儿童导致急刹
工单描述：
自动填入：
case 的事件脚本（LLM 生成的自然语言描述）；
核心指标（MPI / MPS / 是否造成 MPD）；
场景信息（道路类型、天气、车速范围、地图要素等）；
关键 Token 序列及时间戳。
附件 / 链接：
对应的 mini log 回放链接；
关键帧截图（如果有）；
数据平台 / 仿真平台跳转链接。
模块归属与责任团队：
直接用自动分类结果填 assign_team；
也可以根据团队维护的路由表二次映射到具体责任人。
紧急程度（优先级）：
不再完全靠人工拍脑袋；
由一套“规则 + LLM”混合策略给出：
如果命中 MPD（资损 / 有人受伤 / 明显危险），直接打到最高级；
如果 MPI / MPS 有明显恶化趋势，在某个园区集中暴露，优先级提高；
否则交给 LLM 在上下文中综合判断成「致命 / 严重 / 一般 / 低」。
最终，Aone 里出现的是一条几乎不用再补充背景信息的工单，
研发点开就能直接干活，而不是先花半小时还原现场。

7.2 自动加入对应团队的仿真回归集
每一类问题本质上都对应一批“典型 case”。
自动提单之后，我们同时会：

把这条 bad_case 加入到对应团队维护的仿真回归集合：
感知团队：典型的误检 / 漏检 / 尺寸估计问题集；
PnC 团队：典型的急刹 / 大转向 / 停车不走；
定位 / 地图团队：典型的跳变、地图缺失场景；
这些集合本身在仿真平台里就是一个个“回归测试集”，
与 CI / 准出流程是打通的。
这样，每一个新发现的问题，不仅有工单，
还自动变成了后续版本必须回归的一条样本。

7.3 多版本共存：用最新准出版本自动跑回归，看问题是否已解决
L4 量产环境一个现实情况是：线上一定是多版本共存，
有些老版本的问题，在新版本上可能已经被修掉了。

为了避免“同一个问题被不同版本重复提单、重复验证”，
我们在 Dify 工作流里这样串联：

1.当某条工单关联的 bad_case 已经被加入回归集合后：

每次有新的“准出版本”上线前，
CI 会自动在仿真平台用最新准出版本跑一遍这批 case。
2.仿真回归结果通过 MCP 接口反馈给大模型 / 工作流：

如果在最新准出版本上，这批 case 全部过掉：
即使线上老版本还存在这个问题，也会标记： > “新版本已修复，老版本问题无需继续推进，只要等待升级。”
如果最新准出版本仍然失败：
工单保持打开状态，继续提醒对应团队处理。
3.对已经上线一段时间的老问题：

工作流会定期检查：
关联的准出版本是否已经通过这批 case 的回归；
一旦确认某个问题在新版本上稳定通过且已大面积升级：
可以自动把工单状态改为“已在版本 X 中修复并验证通过”，
甚至直接 Close（视团队流程而定）。
这样，多版本共存不再变成“大量重复劳动 + 无穷无尽的追问”，
而是由仿真回归 + 工作流自动回答：

“这个问题在最新准出版本上是不是已经被解决了？
如果解决了，老版本就不要再反复折腾。”
7.4 用 Dify 串起 LLM + RAG + MCP：把系统接口当“工具”用
整条链路看下来，其实大模型做的是“脑”，
但真正跑腿的是一堆具体系统：

数据平台（FastDM / 标签库 / case 库）；
仿真平台（导入 case、触发回归、拉结果）；
Aone（创建 / 更新工单）；
各种内部服务（版本信息、责任团队路由表等）。
为了不让 LLM 变成“写文案的挂件”，
我们用开源的 Dify 把这一堆能力串成一个完整工作流：

每个外部系统的接口（REST / RPC）都被封装成一个 MCP 工具；
LLM 在 Dify 流程里看到的是“可以调用的一组函数”：
create_aone_ticket(...)
add_case_to_sim_suite(...)
query_latest_release_version(...)
update_ticket_status(...)
RAG 知识库中存的是：
Trigger 文档；
case 字段含义；
各团队负责模块说明；
历史问题的处理经验等。
工作流大致逻辑是：

识别异常 → 找到对应 bad_case → LLM 归因 & 分类 →
调用 MCP 创建工单 + 更新仿真回归集 →
等待仿真回归结果 → 再次调用 MCP 更新工单状态。
整条链路从工程角度看非常干净：
系统之间是接口对接，大模型只是决策层的“胶水”和“翻译”。

7.5 钉钉机器人前端：运维在群里发截图就能拉起工作流
为了让一线运维 / 运营真正用起来，我们没有要求大家登陆各种平台点来点去，
而是做了一个很简单的入口：钉钉机器人。

在每个关键运维群里，都拉了这个机器人进来；
当运维同学遇到一个现场问题：
直接在群里发一张截图（云端座舱画面 / 报错界面）；
顺便打一两句自然语言描述；
机器人后面的工作流会做几件事：
用多模态大模型（VLM）理解这张截图 + 文本；
去数据平台里自动对齐到对应的 case_id / 时间窗口；
根据问题初筛的结果判断优先级以及创建对应数据上传任务
数据上传之后跑云端的分析trigger并且生成该 case 的 Token / 秒级标签 / Trigger 结果；
调用问题分类的工作流：
自动归因 + 分类；
自动提 Aone 工单；
自动加入仿真回归集；
把工单链接和回放链接回贴到钉钉群里。
运维同学看到的是：

“我只是在群里说了一句‘这辆车刚才莫名其妙急刹了一脚’，
结果工单已经在 Aone 里起好了，仿真回归也准备好了。”
而一线研发同学看到的是：

群里的“打扰”本质上已经被机器人“缓冲 +结构化”了一遍，
收到的是一个已经带齐现场信息、分类结果和回放链接的工单，
而不是一堆零散的“兄弟你帮我看下这个”。
这就是“自动分类 → 自动提单 → 自动回归 → 自动 Close”的工单闭环。

八、自动分类准不准？用研发的“反手一刀”来评估
自动分类是不是靠谱，不能靠“感觉还行”，
而是要用事实数据说话。

我们的评估方式是：

1.只统计有“研发反馈”的 case

每个 bad_case 最终会落到问题管理系统；
我们只看“研发同学有回复”的问题：
有人认领说明这是他们认可的真实问题。
2.看研发是否修改了模块 / 类型标签

自动分类结果也会显示在问题单里；
如果研发认领后：
不改模块 / 类型 → 认为这次分类正确；
修改了模块 / 类型 → 认为这次分类错误，记为 bad case。
3.把这些“被改掉的 bad case”，反向喂给 LLM

把 Token 序列 + 研发最终结论一起写回 LLM 的 few-shot / RAG 知识库；
让下一轮分类更接近真实使用习惯。
这样，自动分类就变成了一个闭环系统：

Trigger 提供稳定的 Token；
LLM 给出初始分类；
研发通过修改问题单提供监督信号；
分类器在使用中持续迭代。
九、从一条条 case 到“头部问题”：聚类只是时间问题
有了：

road_case / bad_case；
秒级标签；
Trigger Token 序列；
自动分类标签（模块 / 类型 / 严重程度）；
以及“是否已经在最新准出版本上回归通过”的状态；
问题聚类与头部问题发现就有了非常扎实的基础。例如：

按模块 / 问题类型 / 场景做 group by，
看一个阶段内各类问题的分布；
把 case 在地图上打点，看哪些路口 / 路段出现频次特别高；
利用 Token 序列模式做聚类 / 统计，
找出一段时间内“重复出现次数最多、影响 MPI / MPD 最大”的那几类问题。
更进一步的 case 相似度聚类、多模态向量检索、自动发现“还没有名字的长尾模式”，
会涉及到向量空间 / Qwen-VL / 多模态 embedding，这一块会专门拆一篇聊。

十、小结：Trigger 框架是数据闭环的“中枢神经”
回头看这一篇，我们其实讲了两层东西：

1.底层：三端统一 Trigger 框架 + Case / Token 体系

解决的是“怎么把异常事件从原始日志中“长”出来”。
2.上层：LLM + 工作流驱动的工单 & 仿真闭环

解决的是“怎么让问题从被发现，到被验证解决，尽量少依赖人肉搬运”。
它把前面几篇搭好的地基串了起来：

数据分级上传 + case / 文件逻辑映射；
每车每秒标签体系；
再到：
Trigger 统一 Runtime；
Case / Token 表；
自动分类；
自动提单；
自动仿真回归；
自动关闭老问题。
从工程视角看：

Trigger 框架是数据闭环的“中枢神经系统”；
上面可以挂 LLM 做分类与归因；
再往上可以挂问题管理、仿真回归、向量检索、世界模型仿真等更高阶能力。
等后面几篇，我们再从“问题发现与提单”继续往前推，
聊聊如何用这些 Case / Token / 标签，去支撑自动聚类、自动评测、自动回归，
把“bug driven”这条路走得更系统、更可持续。