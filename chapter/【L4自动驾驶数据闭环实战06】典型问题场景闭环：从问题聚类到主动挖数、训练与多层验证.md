前情提要：
01：我们先选好了整个组织的 Loss Function——MPI / MPS / MPD 等一级指标。
02：用心跳 + Microlog，把这些体感指标做成了可统计、可监控的一级指标。
03：在车端做了分级上传、Road Case / Bad Case 映射，打好了数据地基。
04：在云端把每车每秒变成了“人群画像”式的秒级标签体系 + FastDM 快速检索。
05：用三端统一的 Trigger 框架 + LLM，做成了自动问题分类、自动报障和自动拉仿真。
到这一步，我们已经可以：

自动发现问题：急刹车、大转向、停车不走等异常体感事件；
自动分类：把问题分给感知 / 规控 / 定位 / 硬件等模块；
自动建 case：知道是哪辆车、哪一分钟、在什么场景下出了什么幺蛾子。
但这还不够。现实里还有几个关键问题：

哪里问题最多、最值得优先解决？
某一类问题“解决了”，我们怎么证明它真的被治好了？
当某些场景真实数据严重稀缺时，怎么“有的放矢”地用生成式 / 仿真数据补上？
在不能全量上传原始数据的前提下，如何利用 Minilog 把场景重建出来再泛化？
这一篇，就围绕一个问题展开：

「我们已经把问题发现和分类做完了，接下来怎么围绕典型问题场景，
去做主动挖数、生成式补数、训练验证和多层级上线闭环？」
一、从 Road Case 到“典型问题场景”：先把病种分清楚
前几篇我们把线上异常都抽象成了 Case：

Road Case：按分钟切分的一段时间窗口，代表一次“在路上出现异常表现”的故事；
Bad Case：从同一个 Road Case 派生出的模块级问题（感知 / 规控 / 定位 / 硬件…）。
每个 Bad Case，我们都会给出三层描述（这个设定非常关键）：

1. 物理世界场景（Scene）
时间：白天 / 夜间 / 黄昏 / 雨雪雾；
地点：十字路口、非机动车道、匝道、园区内部、地下车库、隧道出口…；
交通参与者：行人、自行车、电瓶车、货车、小客车等；
环境特征：雨后水坑反光、强背光、逆光光斑、施工锥桶、道路坑洼、窄路会车等。
2. 系统表现现象（Phenomenon）
急刹车、频繁点刹；
横向画龙、大幅方向修正；
停车不走（1min / 3min / 10min / 30min 分象限）；
跟车距离异常小、跟随慢速行人过长时间等。
3. 潜在根因（Cause）
感知漏检 / 误检：红色消防栓被当成突然冲出来的小孩；
规划策略过于保守：后车很近仍强烈刹车，不尝试缓刹 + 绕行 + 提醒；
定位抖动：车辆轨迹频繁贴近马路牙子，触发安全策略急刹；
传感器问题：激光雷达污渍 + 夜间灯光 → 有效点数骤降 → 类“致盲”现象；
底盘 / 机械问题：长期走坑洼道路，转向机变形，导致高频画龙。
在现实里，研发同学就是这么交流问题的——

「在非机动车道，密集电动车擦身时，横向避让过于保守导致频繁急刹。」
我们做的事情，就是把这些“口头病历”，变成三元组：Scene–Cause–Phenomenon，再加上秒级标签特征，让机器也能“看懂”。

二、两阶段聚类：先粗分“科室”，再细分“病种”
当每一个 Bad Case 都有了结构化描述后，就可以对它们做聚类了。

1. 第一阶段：规则分桶（粗分科）
利用秒级标签体系 + FastDM，先把 Case 粗略分桶：

按 现象 Phenomenon 分：
桶 A：急刹车相关；
桶 B：横向画龙相关；
桶 C：停车不走 / 龟速相关。
再叠加 场景 Scene 标签：
“急刹车 + 高速干线”；
“急刹车 + 园区非机动车道”；
“停车不走 + 城市十字路口 + 红绿灯异常”。
视情况加入部分 Cause 线索：
「疑似感知误检」类；
「疑似规划保守」类；
「疑似定位波动」类…。
这一步完全是规则化分桶，本质上就是你在 FastDM 上勾勾选选 —— 在什么场景、发生什么现象、带什么先验原因。

2. 第二阶段：Embedding + 聚类（细分病种）
在每个粗桶内部，再做一轮精细聚类：

特征可以来自于：
Case 中关键帧的图像 / 点云 Embedding（CLIP / Qwen-VL 等）；
秒级标签拼成的高维向量（场景 / 行为 / 诊断标签）；
Trigger 生成的“语义 token”序列转成的向量。
聚类方法可以很工程：
k-means、层次聚类、DBSCAN、KNN + 阈值聚类，都足够好用。
这样，每个粗桶里都能拆出若干类非常典型的“病种”，比如：

「雨后夜间，雷达污渍 + 大灯光斑 → 感知误检‘突然出现的行人’ → 急刹车」；
「非机动车道，外卖小哥极近距离擦身 → 规控横向过于保守 → 横向画龙 + 急刹」；
「某固定路口红灯亮、绿灯不亮 + 等待超时逻辑 → 长时间停车不走」；
「某条坑洼路段 → 长期转向机受力变形 → 日常画龙幅度明显高于车队平均 → 主动运维预警」。
这些簇，就是我们说的典型问题场景。

三、典型问题场景要“落地”，必须有可执行 Profile
为了不让“典型问题场景”停在 PowerPoint 上，我给每一类场景都定义了一份 场景 Profile，里面必须包括：

结构化标签规则
例如：「雨夜 + 车速 > 30km/h + 有强反光 + 发生急刹车」；
用标签名 + 取值范围，刻画这类场景的大致边界。
可下发的 Trigger 模板（FastDM的标签组合）
把关键时序条件固化为 Trigger 逻辑：
连续 N 秒激光雷达有效点数骤降；
规划轨迹在某种车道几何下频繁贴边；
障碍物 box 在短时间内剧烈跳动等。
目标数据类型与优先级
必选：Microlog + Minilog；
视需要：原始相机 / 点云、远程座舱语音文本等；
优先级：是否进黑匣子、是否只保 Minilog、不保 Raw 等。
一旦每个场景簇都存在这样一份 Profile，它立刻就变成了可执行的配置：

“在这些状况下发生的问题，上传这些日志 / 传感器数据，优先级是几级”。
四、从“哪里问题多”到“主动多挖点这个场景的数据”
有了典型问题场景和场景 Profile，接下来就是主动挖数。

1. 场景 Profile → 采数策略：标签 + Trigger 一键下发
对每一个场景簇，我们都会自动生成并下发一份采数策略：

用秒级标签规则，在 FastDM / 数仓里做历史数据回捞；
用 Trigger 模板，下发到车端 / 云端做在线筛选；
指定需上传的数据类型（Microlog / Minilog / Raw 等）。
有点像你给每个“病种”都开了一张“检查单”：在什么情况下，做哪些检查。

2. 用场景级指标给每个“病种”打优先级
前几篇搭的指标体系在这时候就派上用场了：

MPI / MPS / MPD 可以按场景拆解，知道：
哪些场景下急刹车多；
哪些场景下 MPD（真事故 / 高风险事件）占比高。
把典型问题场景叠加上去，我们就能算每一个“病种”的：

出现频率；
MPD 贡献（风险权重）；
当前已有样本量（多少条、多少已标注）。
因此完全可以给每类场景打一条类似的采数优先级：

采数优先级 ≈（风险权重 × MPD 贡献）÷ 已有样本数
高风险 + 样本少 → 提高采数权重，多挖；
风险一般 + 样本已经很多 → 压缩采数量，避免浪费。
五、上传量管理：每个场景都有自己的“流量预算”
主动挖数是“花钱”的：流量钱、存储钱、人力钱。

好在之前我们已经有了：

CaseID ↔ 20 秒物理分片文件 的映射；
每个文件片段有唯一 ID + 大小；
可以统计出：某个场景 / 某个 Trigger / 某个项目 在一段时间内上传了多少数据。
于是就可以做三件事：

按场景统计流量与样本利用率
某一类典型场景：
过去一个月一共采了多少个 Case；
上传了多少 GB 数据；
真正被用于标注 / 仿真 / 训练 / 回归的比例是多少。
为每一类场景配置“样本目标 + 流量上限”
比如「雨夜光斑误检」场景：
希望先采满 200 条高质量样本；
每月上限 N GB；
Microlog + Minilog 全保，Raw 只保 Top-K case。
动态调整优先级
样本不足 + 流量未超 → 继续采数；
样本已达标 / 流量超限 → 自动降低优先级、甚至暂停采数。
这样，主动挖数就从“拍脑袋想挖啥就挖啥”，变成了场景级有预算控制的投资决策。

六、规则时代：典型问题场景怎么真正“驱动问题解决 + 仿真验证 + 上线闭环”？
前面几节更多回答的是：

哪里问题多？这些场景要多挖些数据。
接下来是很关键的一步：这些数据挖上来之后怎么用，才能真正把问题解决掉，并且验证干净？

1. 感知链路：定向挖数 → 增值标注 → 定向训练 → 版本对比评测
以感知为例，典型问题场景驱动的链路大致是这样的：

选场景簇
挑出若干风险高 / 业务价值高 / 样本稀缺的场景簇。
定向挖数 + 真值标注
按场景 Profile 挖更多这类场景的样本；
在这些样本上做更精细的真值标注（尤其是漏检很难提前预知的位置）。
定向训练新感知模型
用这批数据做增量训练 / Fine-tune；
同时监控整体误检情况，避免“只顾涨召回，误检炸掉”。
两级评测
真值评测集：在这些场景上的召回率 / 误检率变化；
版本间逐帧对比：同一帧上，新旧版本输出不一致的地方，
必有一对一错或两错，通过抽样 + 人审确认“涨是真涨”。
场景级回归集固化
把典型场景簇对应的部分数据固化成场景级回归集，
每一个新模型版本都必须在这批数据上跑一遍。
上线发版卡口
在这些场景上的表现必须明显变好或至少不变差；
在其他关键场景上不能出现大面积退化。
简化来说，就是让每类典型问题场景都对应一条：

「多挖一点 → 多标一点 → 训练 → 在这类场景上必须变好 → 在其他场景不要变差」 的感知闭环。
2. 规控链路：典型场景集 → 规则演进 → 仿真回归
对规划控制（PnC）来说，典型问题场景的作用更直观：

构建场景集
把典型场景对应的 Case 导入仿真平台；
形成针对某类问题的场景集：
“后车跟车很紧 + 前方突然误检障碍”的一组场景集；
“非机动车道密集电瓶车擦身”的一组场景集；
“红绿灯故障导致长时间停车不走”的一组场景集。
规则 / 策略迭代
在这些场景上迭代 PnC 策略：
比如误检场景下，尝试“缓刹 + 闪灯提醒 + 观察后车距离再决定是否重刹”；
在电动车密集场景下，按照不同速度段调整避让缓冲距离等。
仿真回归评测
每次策略调整，都在这些场景集上做仿真回归：
看体感指标（急刹、画龙、停车不走）是否改善；
看其他常规场景是否被顺带搞坏。
小规模灰度 + 线上指标回收
在少量车 / 小区域灰度，监控真实场景下的 MPI / MPS / MPD 变化；
成功再逐步推大范围。
七、场景太少怎么办？——生成式数据：从“拍脑袋造场景”到“基于典型问题场景的定向生成”
一个现实问题是：有些典型问题场景非常少见，但风险又很高，比如：

极端天气下的某种特殊反光；
非常罕见、但特别危险的路权争夺行为；
地域性极强的怪异路口设计等。
光靠实车跑，很难在短时间内攒齐足够多的样本，这时候就离不开生成式 / 仿真数据。

1. 行业内常见做法：仿真 / 合成数据补稀缺场景
业界已经有不少关于“用合成数据补实车数据”的实践：

通过高精度仿真引擎和传感器模拟生成物理一致的仿真数据，用于感知训练和验证；
基于真实场景构建虚拟 3D 世界，在其中生成与真实分布接近的合成训练数据，补充困难场景；
在学术界，场景生成 / 场景变异也逐渐被视为自动化测试与训练的重要工具。
简单总结：合成数据不是替代真实数据，而是针对稀缺但重要的场景做“有的放矢”的补充。

2. 我们的思路：基于典型问题场景 + Minilog 的“重建 + 泛化”生成
我们这边在生成式数据上的做法，有两个关键点：

不是拍脑袋编场景，而是从典型问题场景出发
聚类得到典型问题场景簇；
每个簇有结构化场景 Profile（各种标签 + Trigger 统计出来的特征）；
有真实 Case 对应的 Microlog + Minilog。
依托 Minilog 做场景“重建 + 泛化”
Minilog 里已经包含了：
车辆姿态（pose）、速度、加速度、航向角；
轨迹、障碍物检测结果、车道线、红绿灯状态等中间结果；
精简压缩后的视频片段；
虽然没有全量原始点云 / 全分辨率图像，但足够重建出场景的几何结构和关键要素。
在仿真平台里，我们可以通过：
用地图 + 障碍物结果还原道路拓扑和障碍物大致位置；
用相机视角、强反光 Trigger 等信息还原光照条件；
用车辆轨迹还原运动学约束。
在这个基础上再做泛化：

例如「雨后光斑误检」场景，可以在仿真中系统地生成：
不同的雨强、道路材质、光斑位置；
不同的车速、跟车距离；
不同的障碍物类型（行人、锥桶、垃圾箱等）。
本质上就是：典型问题场景 + Minilog 提供“骨架”，仿真 / 生成系统在这个骨架上做“肌肉和皮肤”的变体生成。

而且在算力有限、无法全量上传原始数据的前提下，这种方式的性价比非常高。

八、现实中的难点：标注成本、PnC 人力与仿真验证的局限
前面说了这么多，看上去闭环链路已经很完整了，但工程上现在还有几个很硬的现实问题，必须诚实摊开来说：

真值标注的成本依然非常高
即使有典型问题场景 + 主动挖数 + FastDM，这些努力更多是为了
> “把有限的标注资源用在更有价值的数据上”。
但一旦进入精细标注环节，尤其是用来做评测集 / 回归集的真值标注，
人工成本依然很高，而且需要对业务和算法都非常熟的“熟练工”，
替换成本也很大。
规则化 PnC 的问题解决依赖大量人力，验证难度很高
感知问题相对“局部”：一帧一帧看 box / mask / score，还算比较开得了环；
PnC 问题则往往涉及长时间交互、行为博弈和场景上下文：
比如“和外卖小哥相遇时到底该怎么让”；
“红绿灯坏的路口等多久合理”；
“后车很近时怎么在安全和体感之间平衡”等。
这些问题需要对场景和人类驾驶行为都很有经验的工程师手工分析，
规则调优本身就是一个强依赖人力、且不易完全形式化的过程。
开环验证对感知还行，但对预测 / PnC 效果有限
基于「录制的传感器输入 → 重放 → 看控制输出」的开环验证，
对感知是有效的：检测、分割、跟踪结果好不好，一眼就能看出来；
但对需要交互的 预测 / PnC 来说，开环很难评估：
其他交通参与者不会对你的控制策略做出反馈；
很多“本应该发生的交互”在录像里根本没有发生。
换句话说，开环能验证输出合理不合理，
却很难验证“如果真的这么开，会不会引出一连串新的连锁反应”。
“完美感知 + 闭环仿真”的真实性又难以保证
另一种常见做法是：用“完美感知”或“理想化对象”喂给 PnC 做闭环仿真，
去看逻辑收敛不收敛、有没有发散、会不会撞东西；
这在逻辑正确性 / 控制稳定性层面非常有价值，但：
感知误差被强行抹平；
预测模型和其他交通参与者的行为也往往过于理想化；
很多真实世界才会出现的“微妙行为”在仿真里根本长不出来。
所以这类仿真更像是“工程安全保障 + 逻辑正确性检查”，
不能直接等价于“线上真实世界表现”。
仿真一致性 & 人工 Review 的工作量依然巨大
不同版本的仿真环境、资产库、行为模型一旦没对齐，
很容易出现“到底是仿真变了还是算法变了”的争论；
真正要做到“仿真结果足够靠谱”，背后往往是成吨的人力在维护场景库、
行为模型参数和仿真配置；
即便如此，很多关键问题还是要靠工程师去逐条 Review 仿真回放，
人工成本依然非常高。
九、实车验证：目前最有效的“闭环试金石”
说了这么多仿真和台架，其实有一点必须摊开讲——目前真正跑下来，最有效的验证方式，还是实车验证，而且数据驱动的价值在这一环上体现得最淋漓尽致。

1. 性能为什么必须靠实车看？
很多人会直觉性地说：“性能可以在台架上测啊”。实际做下来会发现：

感知性能
从硬盘读日志回放图像 / 点云，和从传感器实时采样，链路是完全不一样的；
I/O 路径不同、缓存行为不同、调度策略不同，
很多性能瓶颈只会在线上真实运行时才暴露出来；
即便采用“传感器注入台架”（把图像从传感器接口灌入，而不是从文件读），
能力也有限，难以完全还原线上各种噪声和抖动。
PnC 性能
台架上的 PnC 测试天生是偏“开环 / 播 log”的：
给一段固定的感知结果序列，让 PnC 算一条轨迹；
大部分时间都走不到各种分支、角落 case；
很多真实线上才会出现的“时序组合 + 边缘分支”，
很难在台架上完整覆盖到。
因此台架更多适合作为：

“固定 log 的回归卡口 + 明显性能退化的早期报警”，
但要真正看性能在真实场景中的分布、尾巴有多长、罕见组合下会不会炸，
最后还是要靠实车——而且必须配合前面所有的数据打点和分析基础设施，用统计的方法看性能。

2. 为什么说“灰度 + 数据闭环”是实测阶段最有效的组合？
在我们的实战里，大致形成了这样一个节奏：

10% 灰度阶段：用数据闭环“疯狂扫雷”
一个新版本上到大概 10% 灰度的时候，
各种问题往往是最密集暴露的阶段：
感知的新误检 / 漏检热点；
PnC 在某些场景下的新退化；
性能瓶颈、资源打满、长尾异常等。
靠传统“人肉看 log”，根本扛不住这么多 case；
现在借助前面几篇搭好的体系：
心跳 / Microlog / Minilog 的体感指标打点；
三端统一 Trigger 自动标出各种异常；
FastDM 秒级标签 + LLM 自动分类聚合；
基本上是跑一天实车 → 第二天自动出一份“路测日报”：
这一天遇到了哪些问题、各类问题的占比；
MPI / MPS / MPD 在各场景的变化趋势；
相比上一个版本，新出的“头部问题类型”是什么。
现实里的一个节奏是：

一个版本常常需要在 10% 灰度期间来回修十几个小版本，
才能把这些集中爆发的问题压下去，准备扩到 40%。
40% 灰度 → 稳定运行 → 100% 全量
当 10% 阶段的问题被“扫雷”得差不多之后，
会逐步扩到 40% 灰度，再观察一段时间；
如果在 40% 阶段各类典型问题场景的占比保持稳定或持续下降，
再进一步扩大到 100%；
这听上去有点“土”：
> “10% 灰度来回修十几个版本、慢慢滚到 100%。”
但在这条路径上，每一步都有数据护航：
哪类典型场景出问题最多；
哪些问题已经明显下降；
哪些问题在新版本反而抬头了；
每一个修复版本带来的实际收益，用指标说话。
3. 实测阶段的数据驱动到底帮了什么？
最直观的几个变化：

QA / 运维从“凭感觉挑 log”变成了看自动生成的路测报告；
头部问题场景通过聚类自动浮出水面，不再全靠“谁吼得大谁优先”；
版本修复的效果不再靠“感觉开起来好多了”，
而是直接看典型问题场景下 MPI / MPS / MPD 的趋势变化。
可以说，在实车验证这个环节里，数据驱动的闭环价值被发挥到了极致：

它既是问题的“传感器”，也是修复效果的“体温计”。
十、小结：典型问题场景 = 从工程闭环走向“训练闭环”的桥
这一篇我们把几个问题串在了一起：

怎么把零散的 Road Case / Bad Case 聚成有工程意义的“典型问题场景”？
怎么围绕典型问题场景，做主动挖数 + 流量管理，让有限的上传只花在刀刃上？
在规则时代，感知和 PnC 如何围绕这些场景做训练 / 仿真回归和上线门禁，真正“解决问题”？
在真实数据稀缺的情况下，如何基于典型问题场景和 Minilog 做场景重建与生成式泛化，而不是凭空造梦？
在标注成本高、PnC 验证难、仿真一致性有限的现实约束下，如何通过多层级验证（尤其是实车验证）把整个工程闭环真正跑起来？
如果把整个组织类比成一个“要被训练的模型”，那么：

MPI / MPS / MPD 是第一篇里定义的 Loss；
秒级标签 / Case / 典型问题场景 是特征空间和样本空间的组织方式；
主动挖数 + 生成式补数 + 仿真回归 + 多层级实车验证 就是“训练步骤”和“验证集”；
最终在车队运行上看到的趋势变化，就是“在线评估指标”。
从这一篇开始，这套「问题驱动的数据闭环」已经不再只是一个工程基础设施，而更接近一条完整的：

问题驱动 → 数据驱动 → 训练驱动 → 体验驱动 的闭环改进链路。
下一篇，就可以在这条工程闭环之上，往前走半步：聊聊在端到端控制（E2E）和世界模型（World Model）时代，这些“典型问题场景”应该怎么用来指导“训什么数据”“多造什么数据”，以及怎么把“问题场景闭环”真正升级成“训练闭环 + 生成闭环”。