前言：看到一个问题有感而发写了一个关于数据闭环的整体的文章，发现引起了很多同学的共鸣，那就再写一写里面我认为很关键的点（踩坑记录），希望也给还在做自动驾驶的各位同学一些不一样的思路。
原问题：目前各家做的自动驾驶数据闭环平台真的闭环了吗？ - 扛枪的回答 - 知乎

目前各家做的自动驾驶数据闭环平台真的闭环了吗？

【数据闭环驱动问题解决·01】
把自动驾驶团队当成一个强化学习模型：
为什么我放弃 MPI，改用 MPS / MPD 做“损失函数”？
2025 年都快结束了，我也来分享一下我们在做数据闭环过程中，踩过的一些坑。

先简单自报下家门：
我在自动驾驶行业做数据相关已经 7 年多了，从最早拿着硬盘从工控机里拷数据，一路做到现在负责一条 L4 物流无人车线上的 数据闭环 & 质量体系。

这几年做下来，我越来越确信一件事：

如果把整个自动驾驶组织想象成一个强化学习模型，
那么我们定义的一级指标，其实就是这个模型的「损失函数 / 奖励函数」。
你告诉这个“大模型”什么是好（奖励），什么是坏（惩罚），
它就会沿着这个方向不断“梯度下降”：
算法怎么改、策略怎么调、运营怎么排、运维怎么干，
都会被这几个指标牵着走。
也就是说：

一级指标选什么，本质上决定了整个组织在往哪儿“收敛”。
而在自动驾驶里，最常被当成“一级指标”的，是 MPI（Miles Per Intervention）。
但我自己的实践结论是：

MPI 很适合拿来汇报和做健康度侧影，
但非常不适合当成「驱动问题解决」的损失函数。
我们现在真正挂在墙上的，是两类东西：

MPS：Miles Per Stupid
——每发生一次「不智能表现」（Stupid 行为），平均跑了多少里程；
MPD：Miles Per Dangerous
——每发生一次「危险行为 / 险情 / 事故」（Dangerous 行为），平均跑了多少里程。
从强化学习视角看：

MPI 优化的是：“人多久来救一次场？”
MPS / MPD 优化的是：“车自己干蠢事 / 干危险事的频率能不能降下去？”
后者，才更接近我们真正想要的“系统表现”。

这篇就来详细讲讲：
为什么我不再用 MPI 做一级指标，以及我们是怎么用 MPS / MPD + 一堆 Trigger，搭出一套真正自我迭代的数据闭环的。

一、先把组织当成一个大模型：一级指标 = 损失函数
先抽象一层。

在我们这条 L4 物流无人车线里，整个「数据闭环」的形态，其实非常像一个强化学习系统：

环境（Environment）：真实道路、园区、天气、路侧设施、其它交通参与者；
Agent：不只是车上的算法，还包括云端调度、远程驾驶策略、运维 / 运营流程；
状态（State）：传感器数据、地图信息、车辆状态、上游系统的各种输入；
动作（Action）：转向、油门、刹车、停车、请求远程接管、通知运维等；
奖励 / 惩罚（Reward / Penalty）：各种「好表现 / 坏表现」事件，被我们打成标签，反馈回各个团队，驱动他们改代码、调策略、改流程。
你可以粗暴地把「整个组织」的更新过程想象成：

车每天在真实环境里跑，产生大量行为轨迹；
通过 Trigger + 指标体系，我们从这堆行为中提取出各种「该奖励 / 该惩罚」的片段；
感知 / 规控 / 地图 / 硬件 / 运维 / 运营等团队，基于这些片段更新自己的「参数」：模型、规则、阈值、SOP；
新版本上线，再看这些指标有没有朝「我们想要的方向」收敛。
在这个视角下：

一级指标就是整个组织共同在优化的「损失函数」。
指标选对了，组织就会 朝你想要的行为分布收敛；
指标选错了，组织会非常努力地「梯度下降」，结果越干越偏。
所以，“数据闭环驱动问题解决”的第一步，其实不是「上了多少 GPU、用了什么大模型」，而是：

先想清楚：
我到底用什么指标来衡量「跑得好不好」？
我到底给整个组织设计了一个什么样的损失函数？
二、为什么 MPI 做不好这个「损失函数」的角色？
先说说行业最常见的那位主角：MPI（Miles Per Intervention）。

定义很简单：

MPI = 总行驶里程 / 接管次数
直觉上很好理解：

MPI 越高，说明「每次人工干预之间跑得越远」；
很多公司会用 MPI 来对外宣传「我们的自动驾驶有多成熟」。
如果把 MPI 当成「全组织的损失函数」，
那大家做的事情其实就是：

让「人类接管的频率」尽可能低。
听上去很合理？
问题是 —— 这是 L2/L3 + 车上有安全员时代的直觉。

我们做的是 L4 物流无人车：

车上 99% 的时间没有人；
出问题的时候，一般是车先「感觉不太对」，
然后主动通过云端系统呼叫远程驾驶员来接管 / 守护。
在这个世界里，MPI 作为「损失函数」，有三个天然缺陷：

接管时刻 ≠ 问题发生时刻（时序严重错位）；
「接管原因」极难被结构化，难以转化成可训练信号；
它优化的是「人多久救一次场」，而不是「车在路上干了多少蠢事 / 危险事」。
1. 远程接管：接管那一刻，往往已经是「忍无可忍」的结果
先看时序问题。

现实中的 L4 远程接管流程大概是这样的：

车自己先在园区 / 道路里跑；
在这段时间里，可能已经发生了各种「体感很差」的行为：
急刹车、画龙、停车不走；
感知抖动、预测乱跳、规控时走时停；
系统根据一套安全规则，觉得「我可能要叫个人来帮忙」；
这时候才发起呼叫，远程驾驶员接入；
人接了管，MPI 统计 +1。
从时间轴上看：

真正「有问题的动作」往往发生在接管前几十秒甚至几分钟前，
接管那一刻只是系统忍无可忍之后的结果。
你如果把损失函数设计成「MPI 越大越好」，实际上是在告诉整个系统：

「尽量少让人来接管。」
这会产生几个很微妙、但很真实的「坏梯度」：

一些策略会倾向于 更晚请求接管 —— 否则你 MPI 看起来就难看；
很多「已经发生但没触发接管的蠢操作 / 危险行为」，
在你的优化目标里是 不可见 的。
从强化学习的话术说，就是：

你把惩罚信号绑在了一个
「延迟且非常间接的事件」（有人按了接管键）上，
而不是绑在真正的「bad action」上。
说明一下：我们也做「接管自动归因」，但不拿它当损失
我们现在内部其实也有一套 接管自动归因：

底层用统一的 Trigger 体系，
把接管前后一段时间内的所有 Trigger 打在时间轴上；
这条「事件时间线」转成大模型能看懂的文本；
用 LLM + RAG 去推理：这次接管更像是感知问题？规控问题？地图/环境问题？远程操作策略问题？
但这套东西在我们的体系里，只承担一个角色：

「这段时间窗优先看一下」的高优先级样本入口。
真正当「损失函数」来优化的目标，是接管前后那一长段里面：

车干了哪些蠢事（Stupid）；
车干了哪些危险事（Dangerous）。
2. 「接管原因」非常难变成稳定的训练数据
第二个问题，是 「接管原因」的采集和结构化几乎做不成一个长期可用体系。

我们基本把能想到的方式都折腾了一遍。

尝试 A：让驾驶员 / 远程司机语音上报「为什么接管」
设计是这样的：

接完管之后按个键，说一句「刚才为什么接管」；
云端语音识别转文字，记录为「接管原因」。
实战体验：

大多数司机没有自动驾驶算法背景，他们能看到的只是表象：
「车辆无故停车不动」；
「刚才无故急刹了一脚」；
但从系统角度，其实 没有真正「无缘无故」的异常：
不是感知误检，就是规则太怂；
不是设施故障，就是环境极端；
只是这些全都藏在内部 log 里，人看不到。
结果就是，我们拿到的「接管原因」，大量是：

「感觉不对」「怕撞到人」「无故停车」「无故急刹」。
对工程分析来说，这些信号 主观、模糊、不可复现，很难变成真正可训练的 reward。

尝试 B：副驾坐工程师，盯日志 + 画面，实时判断
这个方案一度看起来很「专业」：

副驾固定坐一个懂系统的工程师；
一边看路，一边看实时日志、可视化面板；
一有接管，就尝试现场判断原因并记录。
现实情况：

成本高得离谱：
一个车配一个工程师，只能短期做专项，无法规模化。
效果出奇地差：
在线日志量巨大，人眼实时看属于心理安慰，
真正靠谱的分析还是要靠事后重放 + 各模块联调。
为了让人看日志开的各种监控本身，会「污染环境」：
实时可视化、额外统计、实时订阅，都会占用算力和带宽，
我们甚至排查出过「副驾监控工具本身就是性能噪声源」的问题。
尝试 C：所有接管片段上传云端，人工统一打标「接管原因」
这是最「严肃」的打法：

所有接管相关的日志 + 视频 + 传感器数据上传云端；
内部搭起一个问题打标平台；
让几位熟练工长期做「接管原因标注」。
短期效果确实不错：

能打出一套还算准的接管原因标签体系。
但问题也同样典型：

成本爆炸：车队规模上去之后，人力和时间都不可控；
经验全在熟练工脑子里：
哪种 log 模式意味着哪类问题，全靠那几个人的「直觉」；
人一走，新人接手，打标正确率肉眼可见地下滑；
很难沉淀为可复用的规则：
规则容易过拟合某个版本；
一次架构升级，半套规则就废了。
用机器学习的话术说，就是：

你想用「接管原因」来构造 reward，
结果发现这是一个 昂贵、噪声大、标注高度依赖个体经验 的信号，
不适合作为长期稳定的损失函数。
三、换个角度：不问「人什么时候出手」，改看「车到底干了什么」
既然「人接管」这个信号不够好用，
那我们就把视角从 「人」 挪到 「车的行为」 上：

不再问「人什么时候救场？」，
而是问「车自己干了哪些蠢事 / 危险事？」
这就是我们现在实际挂在墙上的两组指标：

MPS：Miles Per Stupid
「每发生一次不智能表现（Stupid 行为），平均跑多少里程？」
实际统计时，我们更常用反写：
每万公里急刹次数
每万公里大转向 / 画龙次数
每万公里停车不走事件次数（按时长分桶）
MPD：Miles Per Dangerous
「每发生一次危险行为 / 险情 / 事故（Dangerous 行为），平均跑多少里程？」
同样，用「每万公里险情 / 事故次数」来表达。
在「损失函数」的语境里可以这么理解：

MPS = 对「蠢行为」的惩罚项（体感很差但未必立刻撞车）；
MPD = 对「危险行为」的重惩罚项（真安全红线）。
整个组织的 self-play 过程，就是围着这两个损失项做「梯度下降」：

在不牺牲任务完成率 / 效率的情况下，
让 MPS / MPD 尽可能低，且任何异常波动都能解释清楚。
最关键的是：
「蠢行为 / 危险行为」本身是可以用 Trigger 精准定义和自动捕捉的，
而不是依赖人拍脑袋。

下面用具体例子展开说。

四、MPS 具体长什么样：急刹、画龙、停车不走
1）急刹车：变坏要查，变好得离谱也要查
急刹这件事，大家都能体会：

坐在车里的感受就是：「哐」一下，整个人往前一冲；
在我们的定义里，急刹是一个严格的 Trigger：
减速度超过某个阈值；
持续时间超过某个阈值；
才会记一次急刹事件。
我们统计的是：

每万公里急刹次数
（按城市 / 场景 / 车型 / 版本等维度拆开）
很多人第一反应是：急刹当然越少越好啊，最好 0 次。

但实践下来，我们现在的共识是：

急刹是体温计，不是清零 KPI。
真正有用的是「急刹曲线什么时候不对劲了」。
我举三个我们真实遇到过的例子：

例子 A：天气降温 → 急刹暴涨
有一次，我们发现某个城市某条线路上：

急刹曲线在几天内突然抬头；
版本没变，场地没变，路线没变。
按「医生的四步走」（望闻问切）来查：

望：多维度看——按车、按时间、按场景拆开；
闻：问现场运营，有没有什么肉眼可见的变化；
问：问算法 / 底盘团队有没有灰度开关；
切：把对应时段的日志 + BMS 数据 + 底盘报文切出来细看。
最后发现真正的原因是：

当地突然降温；
低温下电池温度偏低，BMS + 制动系统里关于能量回收的逻辑被触发；
在某些速度 / 载重工况下，制动力更容易「超调」；
体感上，就变成了「急刹变猛、变多」。
这个问题，在事前你很难靠脑补想到。
但只要你有「每万公里急刹」的体感指标，一旦曲线抬头，就有机会顺藤摸瓜把它揪出来。

例子 B：雨天急刹反而明显减少 → 激光雷达「半瞎」
另一个更加反直觉的例子：

按常识，下雨天感知难度上升，误检更多；
大家直觉上会认为「雨天急刹应该变多」。
结果我们在数据上发现：

某几台车在雨天的「每万公里急刹次数」反而明显 下降；
而且跟任何版本 / 策略更新都对不上。
这种就是我们常说的「好得离谱」，也是要重点排查的。
我们把这批车的数据单独拉出来分析，发现：

平时这些车的激光雷达外壳上积了不少灰；
一下雨，灰 + 水在雷达表面形成了一层「膜」；
激光发射能量被削、回波点数减少；
再加上雨天很多障碍物表面更光滑，漫反射降低；
最终表现为——雷达「部分致盲」，很多障碍物没看见。
以前会触发急刹的障碍物，现在被漏检了：

感知眼里「前面没东西」；
规划觉得「环境很干净，不需要刹车」；
急刹指标就「好看」了；
但其实：

急刹指标变好，风险是实打实上去了。
后来我们的做法是：

加上激光雷达有效点数监控：
点数突然持续减少，直接降速 + 告警；
运维侧收到告警：
主动安排擦雷达 / 检查设备，而不是等出事。
这个例子很典型地说明：

体感指标不是绝对值好看就行，
关键是：任何「变坏」和「好得离谱」，都要能被解释清楚。
例子 C：被追尾——算法都「各有道理」，人觉得离谱
还有一种我们经常见到的情况：

我们的车被后车追尾，比我们追别人尾多得多。
从系统内部看：

感知说：「我前面有障碍物」；
规控说：「前面有障碍，我必须刹车，这是安全第一原则」。
从后车司机的视角看：

他可能在看手机、走神；
抬头一看，前面明明空着，你的车突然急刹；
他的认知就是：「你这车无故急刹」。
这种情况下：

如果你只盯 MPI，统计的是「有没有人接管」；
你会完全看不到这类「别人追尾我们」的急刹风险聚集在哪里。
但如果你有：

「每万公里急刹次数」；
「其中前方无真障碍 + 被后车追尾的子集占比」；
你就可以针对这些「客观上造成危险的急刹」，
单独拉一套样本出来分析：

是感知误检？
还是规控策略太激进？
能不能在后车跟车太近时，更偏向缓刹 + 亮灯提醒？
某些场景能不能优先绕行？
这才是「损失函数」真正给到的梯度方向。

2）画龙：从体感「不稳」到主动运维的入口
第二类常见的 MPS 事件，是 大转向 / 画龙。

现象很好理解：
在一段本应该直直过去的路上，车却总是在左右小幅修正，整体轨迹抖得像条龙。

背后常见原因包括：

标定略偏；
胎压不对；
控制参数超调 / 欠调；
车道线 / 边界线识别抖动，导致规划轨迹不断重算。
我们统计的是：

每万公里大转向 / 画龙事件次数
（同样按城市 / 场景 / 车型 / 版本拆开）
更有意思的是，画龙还帮我们发现过 纯物理世界的「慢性病」。

例子：长期碾坑 → 转向机轻微变形 → 某几台车画龙异常
有些园区路况确实不太好：

某些车每天都要压着同一个坑 / 减速带过去；
大部分车没事，但时间长了个别车就出问题。
在数据上表现出来就是：

同一个场景、同一条路线、同一版本；
车队中大多数车「每万公里画龙次数」都在一个合理区间；
只有少数几台车，画龙指标长期偏高。
把这些车单独拉出来检查，会发现：

转向机构 / 悬挂存在轻微变形或松旷。
人开的话，会感觉「方向有点虚、有点飘」；
但 L4 无人车上没人握方向盘，这种变化是无法被主观感知到的。
系统的行为就是：
「我偏了 → 我修一下 → 又偏了 → 再修一下」，
最后在轨迹上就表现为 异常密集的画龙行为。

于是我们现在的流程是：

每天按 VIN 统计画龙指标；
自动把「画龙事件率异常高的几台车」拉出清单；
给运维团队，做重点检查和保养。
这就是一个典型的：

把 MPS_steer 当损失函数，
直接反向更新到了「硬件运维策略」的例子。
3）停车不走：分时长分象限看，不然全被拥堵噪声淹没
第三类典型的 Stupid 行为，是 停车不走。

对体验和运营的打击不用多说：

客户看着着急；
运营看着抓狂；
技术看着头疼，因为原因谱太复杂了。
我们不会简单看「停车不走次数」，而是：

每万公里停车不走事件数（按时长分桶）
大致会分几个档：

0–1 分钟：很多是正常起停 / 礼让；
1–3 分钟：偏长，主要看整体趋势；
3–10 分钟：可疑，值得具体分析；
10–30 分钟 / 30 分钟以上：基本可判定为严重异常。
实际原因常见的几类：

纯客观交通原因：
前方长时间堵车；
超长红绿灯相位；
大车缓慢掉头 / 转弯挡路；
其他交通参与者行为：
违规停车占道装卸货；
行人 / 电动车一直在车前乱穿；
设施 / 环境异常：
信号灯坏了：红灯亮，绿灯不亮，或者干脆整组灭灯；
道闸不抬杆、门禁 / 扫码 / 人脸识别系统卡死；
地图 / 规则理解问题：
地图上是通路，现实被铁栏杆封死；
现实变成单行 / 临时封路，导航还让车往前冲；
复杂路口的让行关系写得过于保守；
系统自我保护逻辑：
多个传感器信息冲突；
某模块健康度自检不过；
频繁异常触发，让系统直接进入「冻结等待人工确认」模式。
例子：坏红绿灯 + 策略打架 → 在路口一停半小时
有一次，我们就遇到过一个非常典型的事故：

某个路口的红灯正常亮，绿灯经常不亮；
车辆的逻辑是：
红灯亮 → 正常等红灯；
所有灯都不亮 → 认为信号灯异常，等待一段时间后请求远程接管。
现实情况变成：

红灯灭了，绿灯没亮 → 进入「灯异常等待 30 秒」；
这 30 秒里，绿灯可能短暂亮了一会又变回红灯；
远程接管没及时接上（人力有限 / 调度延迟）；
又回到「正常等红灯」的逻辑；
如此循环往复。
最终效果就是：

这辆车在路口，一停就是半小时。
如果没有「每万公里 3 分钟以上停车不走事件数，按路口拆分」这种指标，
这类问题很容易就被归结为一句模糊的吐槽：

「那个路口好像老堵。」
然后就没下文了。

五、MPD：Miles Per Dangerous —— 把安全红线也放进损失函数
说完 MPS（Stupid 行为），再说两句 MPD（Dangerous 行为）。

相比 MPS，MPD 关注的是接近事故的那一小撮事件：

真事故 / 剐蹭 / 被追尾；
高速下的高风险急刹（后车 TTC 极短）；
失控倾向、持续打滑；
持续多次的碰撞预警等。
这些事件的特点是：

数量很少；
每一条的「惩罚权重」都非常高。
在我们的实际流程里，MPD 事件基本都会触发：

单独拉样本集合；
做多模态回放（视频 + 点云 + 轨迹 + 控制命令 + 车身状态）；
从感知 / 预测 / 规控 / 硬件 / 地图 / 环境 / 运营多个维度做复盘；
最终落到明确的策略 / 参数 / 结构性改动上。
在损失函数里，你可以把它理解为：

MPS = 体验惩罚项（车表现得蠢、不智能、不舒服）；
MPD = 安全惩罚项（真触碰安全边界）。
整个系统的目标就是：

让 MPD 尽可能趋近于 0；
同时用 MPS 去约束不要通过极端方式「压低 MPD」：
不能靠「啥都不动」来不出事故；
也不能靠「看不见就当没事」。
六、回到强化学习的比喻：好的指标 = 好的损失函数
现在再回头看一眼我们一开始的类比：

「我想做的是一个自我迭代的系统，类比强化学习，
给出目标和损失函数就很重要。」
这放到自动驾驶数据闭环里，其实就是：

把整个组织当成一个大模型；
一级指标就是我们给它设定的损失函数 / 奖励函数；
MPI 更像是在优化「人多久出手救一次场」；
MPS / MPD 更像是在优化「车在真实世界中干蠢事 / 干危险事的频率」。
从工程可用性来看：

MPS / MPD 的信号更加「贴行为」
Trigger 可以统一定义这些行为；
每个事件都对应完整上下文（micro log / mini log + 视频 + 传感器）；
可以直接喂给规则引擎 + 大模型做自动归因和问题分发。
一级指标必须少而有力
我见过太多「动辄列二三十个指标交给数据团队」的场景：
数据团队辛辛苦苦都做了，最后这些指标的主要用途是——
> 年终汇报 PPT 截图两页。
真正能「当损失函数使唤」的一级指标，
一般不超过三五个，而且大家每天都盯着看。
好的指标天然带有「梯度方向」
每万公里急刹 / 画龙 / 停车不走 / 险情，在什么场景抬头，是可以拆解和优化的；
「指标什么时候变坏 / 好得离谱」，会自然引导资源往最有价值的问题上投；
这才是一个组织级强化学习系统应该有的行为。
七、小结：先把「损失函数」选对，数据闭环才有意义
用一句稍微「上点逼格」的话收个尾：

在「数据闭环驱动问题解决」这件事上，
一级指标 = 组织的损失函数。
你用什么来惩罚 / 奖励，
决定了整个团队会往哪儿收敛。
如果你把 MPI 当成核心指标，
全公司优化的是「人多久来救一次场」；
如果你用 MPS / MPD 这种以「行为表现」为中心的指标，
全公司优化的是「车在真实世界里干蠢事 / 干危险事的频率」。
在这个系列的后几篇，我会再聊：

在这个损失函数之下，Trigger / 标签体系怎么设计；
问题怎么自动路由到合适团队，而不是「所有人都被 @」；
生成式数据在哪些地方真有用，哪些地方更多是自嗨。
但无论后面怎么展开，第一步永远是今天这件事：

先把「全组织的损失函数」——也就是一级指标，选对。
如果你现在也在搭数据闭环、做自动驾驶 / 无人车相关的系统，不妨回头看一眼：

你挂在墙上的一级指标，更像 MPI，还是更像 MPS / MPD？
它们，是在鼓励「少报问题」，还是在鼓励「多发现问题、多关掉问题」？
它们，真的在给整个组织一个正确的梯度方向吗？